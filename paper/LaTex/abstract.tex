This paper presents a method to achieve complex video annotation without requiring improved annotation tools, experts nor trained workers. In this method, the complex annotation process is divided into a set of simple annotation microtasks, and based on them is defined a workflow for generating complex annotation. Each of these microtasks is treated as a human computation function, producing an output that can be used as input to the next microtask in the workflow. In this way, the complex annotation production workflow is treated as a human computation algorithm. To demonstrate the operation of the method was developed a video enrichment system and was carried out an experiment in which the crowd was responsible for: 1. identify the points of interest; 2. suggest extra content; 3. Select the best content for each point of interest; and 4. position them in the scenes. This system was built using the framework developed to support the method and that can handle contributions from internal groups, public groups, and platforms such as Amazon Mechanical Turk, Crowdflower, and Microworkers.




%This paper presents an updated and improved version of CrowdNote, a method to achieve complex media annotation without requiring trained workers nor experts. This method allows the use of simple annotation tools rather than complex and expensive annotation systems. The complex annotation process is divided into a set of simple annotation microtasks, and based on them is defined a workflow for generating complex annotation. Each of these microtasks is treated as a human computation function, producing an output that can be used as input to the next microtask in the workflow. In this way, the complex annotation production workflow is treated as a human computation algorithm. To demonstrate the operation of the method was developed a video enrichment system and was carried out an experiment in which the crowd was responsible for: 1. identify the points of interest; 2. suggest extra content; 3. Select the best content for each point of interest; and 4. position them in the scenes. This system was built using the framework developed to support the method and that can handle contributions from internal groups, public groups, and platforms such as Amazon Mechanical Turk, Crowdflower, and Microworkers.



%This paper presents an approach to perform crowdsourcing media annotation based on a refined version of the CrowdNote method. This method aims to produce complex media annotation without requiring trained workers nor experts. It consists of dividing complex annotation tasks into simple and small microtask processes and cascading them to generate a final result. Each microtask process follows a standardized workflow and produces a partial result that can also be an outcome. Moreover, this approach allows using simple annotation tools rather than complex and expensive annotation systems. Also, it tends to avoid activities that may be tedious and time-consuming for workers. To demonstrate the approach was developed a crowdsourcing video enrichment application, in which four different microtasks processes were cascaded to produce enriched versions of raw videos. In the process, extra content such as images, text, hyperlinks and other elements are applied in the video enrichment. The application was built based on the CrowdNote Framework that provided the process manager, the annotation tools, the aggregation methods, besides a presentation system for the annotated videos. 
%This paper presents an improved version of CrowdNote, a method to achieve complex media annotation without requiring trained workers nor experts. This method allows using simple annotation tools rather than complex and expensive annotation systems. Also, it tends to avoid activities that may be tedious and time-consuming for workers. The complex annotation' process is divided into a set of simple annotation microtasks, and based on them is defined a workflow to generating complex annotation. Each of these microtasks is treated as a human computation function, producing an output that can be used as input to the next microtasking in the workflow. In this way, the complex annotation' production workflow is treated as a human computation algorithm. To demonstrate the operation of the method was developed a video enrichment WEB system, and was carried out an experiment in which the crowd was responsible for: 1. identifying the points of interest; 2. suggest extra content; 3. Select the best content for each point of interest; and 4. position them in the scenes. This system was built using the framework developed  to support the method and that can handle contributions from internal groups, public groups and platforms such as Amazon Mechanical Turk, Crowdflower and Microworkers.


