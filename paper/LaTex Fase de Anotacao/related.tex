


Crowdsourcing media annotation approaches are used in various applications and are used to gather information of various types, such as temporal synchronization\cite{wu2014crowdsourced}, events\cite{Kim:2014:JSL:2679600.2680027}, scene objects\cite{vidwiki2014}, emotions\cite{sanchez2015mood}, actions\cite{desell2015effectiveness}, quality\cite{han2014quality}, geo-tagging\cite{chen2015crowd}, social relevance\cite{santos2014towards} and captions\cite{deshpande2014crowdsourcing}. 

However, some of these works are based on complex annotation tools, demanding hard, tedious or time-consuming tasks, or requiring trained and skilled workers. Some relevant examples that should be regarded include works such as \cite{vidwiki2014,Vondrick:2013:ESU:2436010.2436013,park2014toward,desell2015effectiveness}.

VidWiki\cite{vidwiki2014} is a complex system to improve video lesson by annotating them, which provides a complex annotation tool that allows the worker to edit video scenes by adding various types of annotations, including LaTex equations. Another interesting paper is the work of C.Vandrick\cite{Vondrick:2013:ESU:2436010.2436013}, in which time-consuming complex tasks were deployed in the Amazon Mechanical Turk\cite{gottlieb2012pushing} demanding specialized workers to perform them. 

While these works often produce interesting results, to adopt complex annotation tools, as well as hard and time-consuming tasks, restrict potential workers and owners capable of developing complex tools. Also, skilled workers usually expect expensive rewards \cite{Dontcheva:2014:CCL:2556288.2557217}.

There are also papers on crowdsourcing media annotation that report the use of simple tools and microtasks that can be done quickly by unskilled workers. These works include \cite{Chen:2017:RIM:3025453.3025969,Kim:2014:JSL:2679600.2680027,gadgil2014web,wu2014crowdsourced,sulser2014crowd}.

The work published by N.Gagil \cite{gadgil2014web} uses a very simple annotation tool that allows the workers to perform an easy microtask, which consists of annotating media with surveillance problems if any of them are found.



%ReTool\cite{Chen:2017:RIM:3025453.3025969} is an interesting related work because it presents a web-based tool for owners to create and publish annotation microtasks and workflows to execute them.

%ToolScape\cite{Kim:2014:JSL:2679600.2680027} is a work that deserves prominence, as it is strongly related to the approach presented in this paper. ToolScape integrates simple annotation tools in which workers can perform a sequence of three microtasks, that was used to extract the step-by-step structure of the instruction videos. Moreover, is presented a design pattern to define the workflow for these tasks.



%The work conducted by Dontcheva \cite{Dontcheva:2014:CCL:2556288.2557217} combined e-learning and crowdsourcing to obtain improved images. The workers can improve their skills in image editing through an interactive step-by-step tutorial and test these skill by improving real-world images submitted by requesters. In the end, the improved images are aggregated to generate an improved image dataset.


This brief discussion about some related works aims mainly to highlight the characteristics of the microtasks, as well as the simple annotation tools used to execute them.